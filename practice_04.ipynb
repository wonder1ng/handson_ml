{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "keras.layers.Dense(10, activation='relu', kernel_initializer='he_normal')\n",
    "\n",
    "he_avg_init = keras.initializers.VarianceScaling(scale=2, mode='fan_avg', distribution='uniform')\n",
    "keras.layers.Dense(10, activation='sigmoid', kernel_initializer=he_avg_init);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.layers.Dense(10, kernel_initializer='he_normal')\n",
    "keras.layers.LeakyReLU(alpha=0.2)\n",
    "\n",
    "keras.layers.Dense(10, activation='selu', kernel_initializer='lecun_normal');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 784)              3136      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 300)               235500    \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 300)              1200      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 100)               30000     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation (Activation)     (None, 100)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 271,246\n",
      "Trainable params: 268,878\n",
      "Non-trainable params: 2,368\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(momentum=0.99), # momentum: 기본 0.99 미니배치가 작을수록 소수점 뒤에 9를 넣어 1에 가깝게 만듦\n",
    "    keras.layers.Dense(300, activation='elu', kernel_initializer='he_normal'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(100, kernel_initializer='he_normal', use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation('elu'),\n",
    "    keras.layers.Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(clipvalue=1.0, clipnorm=1.0)\n",
    "# clipvalue=1.0: loss의 모든 편미분 값을 -1.0 ~ 1.0으로 잘라냄.\n",
    "# clipnorm=1.0: 해당 값 기준으로 정규화\n",
    "# 두 인자 모두 기입 시 norm을 먼저 적용\n",
    "model.compile(loss='mse', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(X, y):\n",
    "    y_5_or_6 = (y == 5) | (y == 6) # sandals or shirts\n",
    "    y_A = y[~y_5_or_6]\n",
    "    y_A[y_A > 6] -= 2 # class indices 7, 8, 9 should be moved to 5, 6, 7\n",
    "    y_B = (y[y_5_or_6] == 6).astype(np.float32) # binary classification task: is it a shirt (class 6)?\n",
    "    return ((X[~y_5_or_6], y_A),\n",
    "            (X[y_5_or_6], y_B))\n",
    "\n",
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_train_full = X_train_full / 255.0\n",
    "X_test = X_test / 255.0\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "\n",
    "(X_train_A, y_train_A), (X_train_B, y_train_B) = split_dataset(X_train, y_train)\n",
    "(X_valid_A, y_valid_A), (X_valid_B, y_valid_B) = split_dataset(X_valid, y_valid)\n",
    "(X_test_A, y_test_A), (X_test_B, y_test_B) = split_dataset(X_test, y_test)\n",
    "X_train_B = X_train_B[:200]\n",
    "y_train_B = y_train_B[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1375/1375 [==============================] - 5s 3ms/step - loss: 0.5488 - accuracy: 0.8273 - val_loss: 0.3828 - val_accuracy: 0.8697\n",
      "Epoch 2/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.3566 - accuracy: 0.8775 - val_loss: 0.3307 - val_accuracy: 0.8832\n",
      "Epoch 3/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.3202 - accuracy: 0.8893 - val_loss: 0.3140 - val_accuracy: 0.8929\n",
      "Epoch 4/20\n",
      "1375/1375 [==============================] - 4s 3ms/step - loss: 0.3004 - accuracy: 0.8967 - val_loss: 0.2933 - val_accuracy: 0.9013\n",
      "Epoch 5/20\n",
      "1375/1375 [==============================] - 4s 3ms/step - loss: 0.2870 - accuracy: 0.9007 - val_loss: 0.2798 - val_accuracy: 0.9048\n",
      "Epoch 6/20\n",
      "1375/1375 [==============================] - 4s 3ms/step - loss: 0.2768 - accuracy: 0.9043 - val_loss: 0.2730 - val_accuracy: 0.9051\n",
      "Epoch 7/20\n",
      "1375/1375 [==============================] - 4s 3ms/step - loss: 0.2683 - accuracy: 0.9086 - val_loss: 0.2675 - val_accuracy: 0.9098\n",
      "Epoch 8/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2616 - accuracy: 0.9108 - val_loss: 0.2636 - val_accuracy: 0.9121\n",
      "Epoch 9/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2555 - accuracy: 0.9120 - val_loss: 0.2564 - val_accuracy: 0.9123\n",
      "Epoch 10/20\n",
      "1375/1375 [==============================] - 4s 3ms/step - loss: 0.2502 - accuracy: 0.9150 - val_loss: 0.2548 - val_accuracy: 0.9133\n",
      "Epoch 11/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2457 - accuracy: 0.9165 - val_loss: 0.2680 - val_accuracy: 0.9098\n",
      "Epoch 12/20\n",
      "1375/1375 [==============================] - 3s 3ms/step - loss: 0.2417 - accuracy: 0.9183 - val_loss: 0.2521 - val_accuracy: 0.9131\n",
      "Epoch 13/20\n",
      "1375/1375 [==============================] - 4s 3ms/step - loss: 0.2375 - accuracy: 0.9193 - val_loss: 0.2517 - val_accuracy: 0.9141\n",
      "Epoch 14/20\n",
      "1375/1375 [==============================] - 5s 3ms/step - loss: 0.2344 - accuracy: 0.9202 - val_loss: 0.2413 - val_accuracy: 0.9165\n",
      "Epoch 15/20\n",
      "1375/1375 [==============================] - 5s 3ms/step - loss: 0.2312 - accuracy: 0.9216 - val_loss: 0.2428 - val_accuracy: 0.9153\n",
      "Epoch 16/20\n",
      "1375/1375 [==============================] - 4s 3ms/step - loss: 0.2282 - accuracy: 0.9216 - val_loss: 0.2381 - val_accuracy: 0.9165\n",
      "Epoch 17/20\n",
      "1375/1375 [==============================] - 4s 3ms/step - loss: 0.2257 - accuracy: 0.9219 - val_loss: 0.2364 - val_accuracy: 0.9150\n",
      "Epoch 18/20\n",
      "1375/1375 [==============================] - 4s 3ms/step - loss: 0.2230 - accuracy: 0.9235 - val_loss: 0.2391 - val_accuracy: 0.9190\n",
      "Epoch 19/20\n",
      "1375/1375 [==============================] - 4s 3ms/step - loss: 0.2202 - accuracy: 0.9242 - val_loss: 0.2407 - val_accuracy: 0.9168\n",
      "Epoch 20/20\n",
      "1375/1375 [==============================] - 4s 3ms/step - loss: 0.2183 - accuracy: 0.9260 - val_loss: 0.2325 - val_accuracy: 0.9180\n"
     ]
    }
   ],
   "source": [
    "model_A = keras.models.Sequential()\n",
    "model_A.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_A.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
    "model_A.add(keras.layers.Dense(8, activation=\"softmax\"))\n",
    "model_A.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "                metrics=[\"accuracy\"])\n",
    "history = model_A.fit(X_train_A, y_train_A, epochs=20,\n",
    "                    validation_data=(X_valid_A, y_valid_A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7/7 [==============================] - 1s 41ms/step - loss: 0.4940 - accuracy: 0.8200 - val_loss: 0.4351 - val_accuracy: 0.8641\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 36ms/step - loss: 0.3594 - accuracy: 0.9450 - val_loss: 0.3553 - val_accuracy: 0.9016\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.2905 - accuracy: 0.9400 - val_loss: 0.3010 - val_accuracy: 0.9381\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.2438 - accuracy: 0.9750 - val_loss: 0.2590 - val_accuracy: 0.9604\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.2081 - accuracy: 0.9850 - val_loss: 0.2305 - val_accuracy: 0.9675\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.1832 - accuracy: 0.9850 - val_loss: 0.2067 - val_accuracy: 0.9706\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.1623 - accuracy: 0.9850 - val_loss: 0.1894 - val_accuracy: 0.9736\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.1469 - accuracy: 0.9850 - val_loss: 0.1737 - val_accuracy: 0.9736\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.1329 - accuracy: 0.9850 - val_loss: 0.1606 - val_accuracy: 0.9757\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.1217 - accuracy: 0.9850 - val_loss: 0.1496 - val_accuracy: 0.9757\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.1123 - accuracy: 0.9850 - val_loss: 0.1408 - val_accuracy: 0.9757\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.1041 - accuracy: 0.9850 - val_loss: 0.1333 - val_accuracy: 0.9767\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0974 - accuracy: 0.9850 - val_loss: 0.1263 - val_accuracy: 0.9787\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.0913 - accuracy: 0.9850 - val_loss: 0.1203 - val_accuracy: 0.9807\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0861 - accuracy: 0.9900 - val_loss: 0.1155 - val_accuracy: 0.9807\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0816 - accuracy: 0.9900 - val_loss: 0.1112 - val_accuracy: 0.9797\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0774 - accuracy: 0.9900 - val_loss: 0.1070 - val_accuracy: 0.9807\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0737 - accuracy: 0.9900 - val_loss: 0.1028 - val_accuracy: 0.9848\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0703 - accuracy: 0.9900 - val_loss: 0.1003 - val_accuracy: 0.9848\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0673 - accuracy: 0.9900 - val_loss: 0.0970 - val_accuracy: 0.9858\n"
     ]
    }
   ],
   "source": [
    "model_B = keras.models.Sequential()\n",
    "model_B.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_B.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
    "model_B.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "model_B.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "                metrics=[\"accuracy\"])\n",
    "history = model_B.fit(X_train_B, y_train_B, epochs=20,\n",
    "                      validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B_on_A = keras.models.Sequential(model_A.layers[:-1]) # output 제외 전체 layer 반환\n",
    "model_B_on_A.add(keras.layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A_clone = keras.models.clone_model(model_A)   # 모델 구조 복사, 가중치는 복제하지 않음\n",
    "model_A_clone.set_weights(model_A.get_weights())    # 가중치 복제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = False # 출력층 제외 가중치 동결\n",
    "# 층을 동결하거나 동결 해제 후 새로 컴파일 필수\n",
    "model_B_on_A.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=4, validation_data=(X_valid_B, y_valid_B))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
