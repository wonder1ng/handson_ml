{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf, os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # 메모리 증가 방지 설정\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "os.putenv('TF_GPU_ALLOCATOR', 'cuda_malloc_async')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.datasets import load_sample_image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "china = load_sample_image('china.jpg') / 255\n",
    "flower = load_sample_image('flower.jpg') / 255\n",
    "images = np.array([china, flower])\n",
    "batch_size, height, width, channels = images.shape\n",
    "\n",
    "filters = np.zeros(shape=(7, 7, channels, 2), dtype=np.float32)\n",
    "filters[:, 3, :, 0] = 1 # 수직선\n",
    "filters[3, :, :, 1] = 1 # 수평선\n",
    "\n",
    "outputs = tf.nn.conv2d(images, filters, strides=1, padding='SAME')\n",
    "\n",
    "for image_index in (0, 1):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for channel in range(channels):\n",
    "        plt.subplot(3, 2, channel+1, title=f'channel: {channel}')\n",
    "        plt.imshow(images[image_index, :, :, channel], cmap='gray')\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(3, 2, 4, title='channel: mean')\n",
    "    plt.imshow(images[image_index].mean(axis=2).reshape(-1, 640, 1), cmap='gray')\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(3, 2, 5, title='output: 0')\n",
    "    plt.imshow(outputs[image_index, :, :, 0], cmap='gray')\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(3, 2, 6, title='output: 1')\n",
    "    plt.imshow(outputs[image_index, :, :, 1], cmap='gray')\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.show(block=False)\n",
    "    plt.pause(2)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = keras.layers.Conv2D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2 = keras.layers.Conv2D(filters=2, kernel_size=7, strides=1,\n",
    "                           padding=\"SAME\", activation=\"relu\", input_shape=outputs.shape)\n",
    "\n",
    "conv_outputs = conv(images)\n",
    "conv_outputs2 = conv2(images)\n",
    "conv_outputs.shape, conv_outputs2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    output = tf.nn.max_pool(images,\n",
    "                            ksize=(1, 1, 1, 3),\n",
    "                            strides=(1, 1, 1, 3),\n",
    "                            padding='VALID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_pool = keras.layers.Lambda(lambda X: \n",
    "                                 tf.nn.max_pool(X, \n",
    "                                                ksize=(1, 1, 1, 3), \n",
    "                                                strides=(1, 1, 1, 3), \n",
    "                                                padding='valid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_avg_pool = keras.layers.GlobalAvgPool2D()\n",
    "global_avg_pool = keras.layers.Lambda(lambda X: tf.reduce_mean(X, axis=[1, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_train, X_valid = X_train_full[:-5000], X_train_full[-5000:]\n",
    "y_train, y_valid = y_train_full[:-5000], y_train_full[-5000:]\n",
    "\n",
    "X_mean = X_train.mean(axis=0, keepdims=True)\n",
    "X_std = X_train.std(axis=0, keepdims=True) + 1e-7\n",
    "X_train = (X_train - X_mean) / X_std\n",
    "X_valid = (X_valid - X_mean) / X_std\n",
    "X_test = (X_test - X_mean) / X_std\n",
    "\n",
    "X_train = X_train[..., np.newaxis]\n",
    "X_valid = X_valid[..., np.newaxis]\n",
    "X_test = X_test[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(64, 7, activation='relu', padding='same', input_shape=[28, 28, 1]),\n",
    "    keras.layers.MaxPooling2D(2),\n",
    "    keras.layers.Conv2D(128, 3, activation='relu', padding='same'),\n",
    "    keras.layers.Conv2D(128, 3, activation='relu', padding='same'),\n",
    "    keras.layers.MaxPooling2D(2),\n",
    "    keras.layers.Conv2D(256, 3, activation='relu', padding='same'),\n",
    "    keras.layers.Conv2D(256, 3, activation='relu', padding='same'),\n",
    "    keras.layers.MaxPooling2D(2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=1024, epochs=10, validation_data=(X_valid, y_valid))\n",
    "score = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:10] # 새로운 이미지처럼 사용합니다\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualUnit(keras.layers.Layer):\n",
    "    def __init__(self, filters, strides=1, activation='relu', **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.activation = keras.activations.get(activation)\n",
    "        self.main_layers = [\n",
    "            keras.layers.Conv2D(filters, 3, strides=strides, padding='same', use_bias=False),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            self.activation,\n",
    "            keras.layers.Conv2D(filters, 3, strides=1, padding='same', use_bias=False),\n",
    "            keras.layers.BatchNormalization()\n",
    "        ]\n",
    "\n",
    "        self.skip_layers = []\n",
    "        if strides > 1:\n",
    "            self.skip_layers = [\n",
    "                keras.layers.Conv2D(filters, 1, strides=strides, padding='same', use_bias=False),\n",
    "                keras.layers.BatchNormalization()\n",
    "            ]\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        for layer in self.main_layers:\n",
    "            Z = layer(Z)\n",
    "        skip_Z = inputs\n",
    "        for layer in self.skip_layers:\n",
    "            skip_Z = layer(skip_Z)\n",
    "        \n",
    "        return self. activation(Z + skip_Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(64, 7, strides=2, input_shape=[224, 224, 3], padding='same', use_bias=False))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Activation('relu'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=3, strides=2, padding='same'))\n",
    "prev_filters = 64\n",
    "for filters in [prev_filters]*3 + [prev_filters*2]*4 + [prev_filters*4]*6 + [prev_filters*8]*3:\n",
    "    strides = 1 if filters == prev_filters else 2\n",
    "    model.add(ResidualUnit(filters, strides=strides))\n",
    "    prev_filters = filters\n",
    "model.add(keras.layers.GlobalAvgPool2D())\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "model.summary();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.applications.resnet50.ResNet50(weights='imagenet')\n",
    "images_resized = tf.image.resize(images, [224, 224])\n",
    "inputs = keras.applications.resnet50.preprocess_input(images_resized * 255)\n",
    "Y_proba = model.predict(inputs)\n",
    "\n",
    "top_K = keras.applications.resnet50.decode_predictions(Y_proba, top=3)\n",
    "for image_index in range(len(images)):\n",
    "    print('이미지 #{}'.format(image_index))\n",
    "    for class_id, name, y_proba in top_K[image_index]:\n",
    "        print('  {} - {:12s} {:.2f}%'.format(class_id, name, y_proba*100))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "dataset, info = tfds.load('tf_flowers', as_supervised=True, with_info=True)\n",
    "dataset_size = info.splits['train'].num_examples\n",
    "class_names = info.features['label'].names\n",
    "n_classes = info.features['label'].num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set, valid_set, train_set = tfds.load(\"tf_flowers\",\n",
    "    split=[\"train[:10%]\", \"train[10%:25%]\", \"train[25%:]\"],\n",
    "    as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image, label):\n",
    "    resized_image = tf.image.resize(image, [224, 224])\n",
    "    final_image = keras.applications.xception.preprocess_input(resized_image)\n",
    "    \n",
    "    return final_image, label\n",
    "\n",
    "batch_size = 32\n",
    "train_set = train_set.shuffle(1000)\n",
    "train_set = train_set.map(preprocess).batch(batch_size).prefetch(1)\n",
    "valid_set = valid_set.map(preprocess).batch(batch_size).prefetch(1)\n",
    "test_set = test_set.map(preprocess).batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = keras.applications.xception.Xception(weights='imagenet', include_top=False)\n",
    "avg = keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "output = keras.layers.Dense(n_classes, activation='softmax')(avg)\n",
    "model = keras.Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "print(len(base_model.trainable_variables), len(model.trainable_variables))\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "print(len(base_model.trainable_variables), len(model.trainable_variables))\n",
    "\n",
    "base_model.trainable = True\n",
    "print(len(base_model.trainable_variables), len(model.trainable_variables))\n",
    "base_model.trainable = False\n",
    "print(len(base_model.trainable_variables), len(model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(learning_rate=0.2, momentum=0.9)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "history = model.fit(train_set, epochs=5, validation_data=valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(base_model.trainable_variables), len(model.trainable_variables))\n",
    "base_model.trainable = True\n",
    "print(len(base_model.trainable_variables), len(model.trainable_variables))\n",
    "\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "history = model.fit(train_set, epochs=3, validation_data=valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
